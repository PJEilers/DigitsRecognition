{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline cnn model for digit\n",
    "import numpy as np\n",
    "#import import_ipynb\n",
    "from loader import Loader\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import BatchNormalization\n",
    "import random as r\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset1():\n",
    "# Dividing the data into train and test data\n",
    "    dataset = Loader()\n",
    "    #trainX, trainY = dataset.getWholeTrainSet(pca=False)\n",
    "    trainX, trainY = dataset.augment()\n",
    "    # noisy dataset for training only\n",
    "    #testX, testY = dataset.getNoisySet(intensity=0.5)\n",
    "    testX, testY = dataset.getWholeTestSet(pca=False)\n",
    "    trainX = np.array(trainX)\n",
    "    trainY = np.array(trainY)\n",
    "    testX = np.array(testX)\n",
    "    testY = np.array(testY)\n",
    "    \n",
    "\n",
    "    testX = testX.reshape((testX.shape[0], 16,15, 1))\n",
    "    trainX = trainX.reshape((trainX.shape[0], 16,15, 1))\n",
    "    testY = to_categorical(testY)\n",
    "    trainY = to_categorical(trainY)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdataset():\n",
    "    \n",
    "    trainX, trainY, testX, testY = dataset1()\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data normalization\n",
    "def normalise_data(traindata, testdata):\n",
    "    traindata = traindata.astype('float32')\n",
    "    testdata = testdata.astype('float32')\n",
    "    train_norm = traindata / 6.0\n",
    "    \n",
    "    # check if test data is on a range of 0-255\n",
    "    test_norm = testdata / 6.0\n",
    "    return train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainX, trainY, testX, testY = getdataset()\n",
    "#train_norm, test_norm  = normalise_data(trainX, testX)\n",
    "#print(train_norm[59])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_definition():\n",
    "    # tune model parameters here\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(16,15, 1)))\n",
    "    #model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    \n",
    "    #model.add(Conv2D(32, (3, 3),activation='relu', kernel_initializer='he_uniform'))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Flatten and apply drop out or apply drop out after Conv2D it is essentially the same\n",
    "    model.add(Dropout(0.50))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    \n",
    "    model.add(Dropout(0.20))\n",
    "    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dropout(0.20))\n",
    "    model.add(Dense(10, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#    model.add(Dropout(0.20))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    #opt = SGD(lr=0.01)\n",
    "    opt = SGD(lr=0.03, momentum=0.9)\n",
    "    #opt = 'adam'\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_modelkfold(mtrainX, mtrainY, folds=10):\n",
    "    accuracies,histories = list(), list()\n",
    "    \n",
    "    # random shuffle k fold validation\n",
    "    kfold = KFold(folds, shuffle=True, random_state=3)\n",
    "    for training_indices, testing_indices in kfold.split(mtrainX):\n",
    "        model = model_definition()\n",
    "        trainX, trainY, testX, testY = mtrainX[training_indices], mtrainY[training_indices], mtrainX[testing_indices], mtrainY[testing_indices]\n",
    "        # so this model.fit reflects the model.fit for only the kfold \n",
    "        #model.fit(trainX, trainY, epochs=120, batch_size=10, validation_data=(testX, testY), verbose=0)\n",
    "        history_kfold = model.fit(trainX, trainY, epochs=150, batch_size=10, validation_data=(testX, testY), verbose=0)\n",
    "        \n",
    "        # returning the validation accuracies of every k fold validation set\n",
    "        _, accuraccy = model.evaluate(testX, testY, verbose=0)\n",
    "        print('%.3f' % (accuraccy * 100.0))\n",
    "        # stores accuracies and test data on last kth model\n",
    "        accuracies.append(accuraccy)\n",
    "        histories.append(history_kfold)\n",
    "        # implement a list for storing all the k fold models. If you wish\n",
    "    return accuracies,histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print the accuracies of the k fold iterations\n",
    "def run_model():   \n",
    "    # runnning k fold\n",
    "    trainX, trainY, testX, testY = getdataset()\n",
    "    trainX,testX = normalise_data(trainX,testX)\n",
    "    # printing the accuracies of the k fold\n",
    "    print('printing the k fold accuracies')\n",
    "    accuracies, histories = train_modelkfold(trainX, trainY)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Training on the whole dataset')\n",
    "    history_trailist = list()\n",
    "    # redefiniton of the model\n",
    "    model = model_definition()\n",
    "    history_training = model.fit(trainX, trainY, epochs=150, batch_size=32, verbose=0)\n",
    "    \n",
    "    history_trailist.append(history_training)\n",
    "    # save model\n",
    "    model.save('final_model.h5')\n",
    "    #_, accuracy1 = model.evaluate(testX, testY, verbose=0)\n",
    "    #print('Test accuracy =',accuracy1*100.0)\n",
    "    \n",
    "    \n",
    "    # running on the saved model on the test set\n",
    "    print('Testing the saved model')\n",
    "    model = load_model('final_model.h5')\n",
    "    # evaluate model on test dataset\n",
    "    _, accuracy1 = model.evaluate(testX, testY, verbose=0)\n",
    "    print('Test accuracy > %.3f' % (accuracy1 * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39, 19, 89, 93, 37, 40, 61, 82, 83, 84, 68, 36, 8, 43, 13, 12, 9, 71, 15, 76, 54, 92, 32, 44, 16, 55, 74, 81, 25, 20]\n",
      "(1000, 16, 15)\n",
      "printing the k fold accuracies\n",
      "98.000\n",
      "98.000\n",
      "95.000\n",
      "98.000\n",
      "98.000\n",
      "97.000\n",
      "96.000\n",
      "97.000\n",
      "96.000\n",
      "99.000\n",
      "Training on the whole dataset\n",
      "Testing the saved model\n",
      "Test accuracy > 98.400\n"
     ]
    }
   ],
   "source": [
    "run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
