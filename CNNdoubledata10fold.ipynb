{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline cnn model for digit\n",
    "import numpy as np\n",
    "#import import_ipynb\n",
    "from loader import Loader\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import BatchNormalization\n",
    "import random as r\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from matplotlib import pyplot\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "from keras.utils.vis_utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns the data in the required format\n",
    "\n",
    "def dataset1():\n",
    "# Dividing the data into train and test data\n",
    "    #clear = lambda: os.system('clear')\n",
    "    #clear()\n",
    "    \n",
    "    dataset = Loader()\n",
    "    noise = 1\n",
    "    print('Noise intensity is')\n",
    "    print(noise)\n",
    "    \n",
    "    trainX,trainY =  dataset.getWholeTrainSet(pca=False) \n",
    "    \n",
    "    \n",
    "    trainXaug,trainYaug =  dataset.augment() \n",
    "\n",
    "    trainXwithnoise, trainYwithnoise = dataset.getNoisySet(intensity=noise, set=\"train\", flat=False, truncate=True)\n",
    "    \n",
    "        \n",
    "    trainXaug1 = np.concatenate((trainX, trainXaug))\n",
    "    trainYaug1 = np.concatenate((trainY, trainY))\n",
    "   \n",
    "    testX, testY = dataset.getWholeTestSet()\n",
    "    \n",
    "    trainX = np.array(trainX)\n",
    "    trainXwithnoise = np.array(trainXwithnoise)\n",
    "    trainY = np.array(trainY)\n",
    "    testX = np.array(testX)\n",
    "    testY = np.array(testY)\n",
    "   \n",
    "    trainXwithnoise = trainXwithnoise.reshape((trainXwithnoise.shape[0], 16,15, 1))\n",
    "    trainXaug1 =  trainXaug1.reshape((trainXaug1.shape[0], 16,15, 1))\n",
    "    testX = testX.reshape((testX.shape[0], 16,15, 1))\n",
    "    trainX = trainX.reshape((trainX.shape[0], 16,15, 1))\n",
    "    # the labels are one hot encoded\n",
    "    testYintegers = testY\n",
    "    trainYaug1 =  to_categorical(trainYaug1)\n",
    "    testY = to_categorical(testY)\n",
    "    trainY = to_categorical(trainY)\n",
    "    return trainXaug1,trainXwithnoise, trainYaug1, testX, testY,testYintegers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdataset1(intensity,dataset):\n",
    "    \n",
    "    trainX,trainXwithnoise, trainY, testX, testY,testYintegers = dataset1(intensity,dataset)\n",
    "    return trainX,trainXwithnoise, trainY, testX, testY,testYintegers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "def model_definition():\n",
    "    # tune model parameters here\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(16,15, 1)))\n",
    "    #model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Flatten and apply drop out or apply drop out after Conv2D it is essentially the same\n",
    "    model.add(Dropout(0.50))\n",
    "    model.add(Dense(240, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    \n",
    "    model.add(Dropout(0.20))\n",
    "    model.add(Dense(120, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dropout(0.20))\n",
    "    model.add(Dense(50, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#    model.add(Dropout(0.20))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    #opt = SGD(lr=0.01)\n",
    "    opt = SGD(lr=0.03, momentum=0.9)\n",
    "    #opt = 'adam'\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfold cross validation\n",
    "def train_modelkfold(mtrainX,mtrainXwithnoise, mtrainY, folds=10):\n",
    "    accuracies,histories = list(), list()\n",
    "\n",
    "    kfold = KFold(folds, shuffle=True,random_state=3)      \n",
    "    for training_indices, testing_indices in kfold.split(mtrainX):\n",
    "        model = model_definition()\n",
    "        trainX, trainY, testX, testY = mtrainX[training_indices], mtrainY[training_indices], mtrainX[testing_indices], mtrainY[testing_indices]\n",
    "        # so this model.fit reflects the model.fit for only the kfold \n",
    "        #model.fit(trainX, trainY, epochs=120, batch_size=10, validation_data=(testX, testY), verbose=0)\n",
    "        history_kfold = model.fit(trainX, trainY, epochs=200, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
    "        \n",
    "        # returning the validation accuracies of every k fold validation set\n",
    "        _, accuraccy = model.evaluate(testX, testY, verbose=0)\n",
    "        print('%.3f' % (accuraccy * 100.0))\n",
    "        # stores accuracies and test data on last kth model\n",
    "        accuracies.append(accuraccy)\n",
    "        histories.append(history_kfold)\n",
    "        # implement a list for storing all the k fold models. If you wish\n",
    "    return accuracies,histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and return models \n",
    "def fitmodel(trainX1, trainY,testX, testY,i):   \n",
    "    \n",
    "    #once the model has been decided on from k fold\n",
    "    model = model_definition()\n",
    "    history_training = model.fit(trainX1, trainY,epochs=200, verbose=0)\n",
    "    # save model\n",
    "    name = \"final_model.h5\" + str(i)\n",
    "    model.save(name)\n",
    "    # load the model\n",
    "    model = load_model(name)\n",
    "    return model,history_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Counts the total number of correctly predicted labels in the test data\n",
    "\n",
    "def modelpredictions(modellist,testX,testY):\n",
    "    \n",
    "    \n",
    "    correctpernoise = []\n",
    "    for model in modellist:\n",
    "        correctaveragepermodel = 0.0\n",
    "        correct = 0.0\n",
    "        preds = model.predict(testX)\n",
    "        preds = np.argmax(model.predict(testX), axis=-1)\n",
    "        #preds = to_categorical(preds)\n",
    "        #print(preds)\n",
    "        \n",
    "        for i in range(len(testY)):\n",
    "            if (preds[i] == testY[i]): # Change\n",
    "                correct = correct+1\n",
    "                \n",
    "        correctaveragepermodel = correct/len(testY)\n",
    "        correctpernoise.append(correctaveragepermodel)\n",
    "        #return list\n",
    "    return correctpernoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final function to gather the average per model\n",
    "\n",
    "def results():\n",
    "    \n",
    "    trainingaccuracypermodel  = []\n",
    "    testaccuracypernoisemean = []\n",
    "    testaccuracyvariancepernoise = []    \n",
    "    numofmodels = 10\n",
    "\n",
    "    dataset = Loader()\n",
    "    traningmean = []\n",
    "    trainingvariance = []\n",
    "    traininglosspernoiseintensity = []\n",
    "    \n",
    "    \n",
    "    kfoldmeanpermodel = []\n",
    "    kfoldvariancepermodel = []\n",
    "    histories = list()\n",
    "    modellist = []\n",
    "\n",
    "    trainX,trainXwithnoise, trainY, testX, testY,testYintegers = dataset1()\n",
    "    print('printing the k fold accuracies with noisy training data')\n",
    "    accuracies, histories = train_modelkfold(trainX,trainXwithnoise, trainY)\n",
    "    print('mean of k-fold accuracies')\n",
    "    print(np.mean(accuracies))\n",
    "    kfoldmeanpermodel.append(np.mean(accuracies))\n",
    "    print('standard of k-fold accuracies')\n",
    "    print(np.std(accuracies))\n",
    "    kfoldvariancepermodel.append(np.std(accuracies))\n",
    "    print('finished k fold')\n",
    "\n",
    "    trainiaccuracy = 0.0\n",
    "    testmean = 0.0\n",
    "    testvariance = 0.0\n",
    "    errorresultpernoise=0.0\n",
    "    trainloss = 0.0\n",
    "\n",
    "    # making  models\n",
    "    for i in range(numofmodels):\n",
    "        trainvariance = 0.0\n",
    "        model,history_training = fitmodel(trainX, trainY,testX, testY,i)\n",
    "        histories.append(history_training)\n",
    "        modellist.append(model)\n",
    "        print('In training')  \n",
    "        #print(type(trainiaccuracy))\n",
    "        trainingaccuracypermodel.append(sum(histories[i].history['accuracy'])/200)\n",
    "\n",
    "\n",
    "        #training mean\n",
    "        traningmean.append(np.mean(trainingaccuracypermodel))\n",
    "        \n",
    "        # training variance\n",
    "        trainingvariance.append(np.std(trainingaccuracypermodel))\n",
    "\n",
    "        \n",
    "        #correct = 0    \n",
    "        print('In testing')\n",
    "        correctpermodel = modelpredictions(modellist,testX,testYintegers)\n",
    "        \n",
    "       \n",
    "        #testmean = (sum(correctpermodel)/numofmodels)*100\n",
    "        \n",
    "        # test mean\n",
    "        testmean = np.mean(correctpermodel)\n",
    "        testaccuracypernoisemean.append(testmean)\n",
    "        \n",
    "        #standard deviation of test accuracy per noise\n",
    "        testvariance = np.std(correctpermodel)\n",
    "        testaccuracyvariancepernoise.append(testvariance)    \n",
    "    \n",
    "    \n",
    "        %reset -f in\n",
    "    return testaccuracypernoisemean,testaccuracyvariancepernoise,traningmean,trainingvariance,kfoldmeanpermodel,kfoldvariancepermodel\n",
    "    #predslist.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise intensity is\n",
      "1\n",
      "printing the k fold accuracies with noisy training data\n",
      "99.500\n",
      "100.000\n",
      "99.750\n",
      "99.500\n",
      "99.750\n",
      "100.000\n",
      "99.750\n",
      "100.000\n",
      "99.750\n",
      "99.500\n",
      "mean of k-fold accuracies\n",
      "0.9975000023841858\n",
      "standard of k-fold accuracies\n",
      "0.0019364898263213358\n",
      "finished k fold\n",
      "WARNING:tensorflow:From /home/gebruiker/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/gebruiker/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: final_model.h50/assets\n",
      "In training\n",
      "In testing\n",
      "Flushing input history\n",
      "INFO:tensorflow:Assets written to: final_model.h51/assets\n",
      "In training\n",
      "In testing\n",
      "Flushing input history\n",
      "INFO:tensorflow:Assets written to: final_model.h52/assets\n",
      "In training\n",
      "In testing\n",
      "Flushing input history\n",
      "INFO:tensorflow:Assets written to: final_model.h53/assets\n",
      "In training\n",
      "In testing\n",
      "Flushing input history\n",
      "INFO:tensorflow:Assets written to: final_model.h54/assets\n",
      "In training\n",
      "In testing\n",
      "Flushing input history\n",
      "INFO:tensorflow:Assets written to: final_model.h55/assets\n",
      "In training\n",
      "In testing\n",
      "Flushing input history\n",
      "INFO:tensorflow:Assets written to: final_model.h56/assets\n",
      "In training\n",
      "In testing\n",
      "Flushing input history\n",
      "INFO:tensorflow:Assets written to: final_model.h57/assets\n",
      "In training\n",
      "In testing\n",
      "Flushing input history\n",
      "INFO:tensorflow:Assets written to: final_model.h58/assets\n",
      "In training\n",
      "In testing\n",
      "Flushing input history\n",
      "INFO:tensorflow:Assets written to: final_model.h59/assets\n",
      "In training\n",
      "In testing\n",
      "Flushing input history\n"
     ]
    }
   ],
   "source": [
    "testaccuracypernoisemean,testaccuracyvariancepernoise,traningmean,trainingvariance,kfoldmeanpermodel,kfoldvariancepermodel = results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.984,\n",
       " 0.9844999999999999,\n",
       " 0.983,\n",
       " 0.9834999999999999,\n",
       " 0.9825999999999999,\n",
       " 0.9818333333333332,\n",
       " 0.982142857142857,\n",
       " 0.98225,\n",
       " 0.9824444444444443,\n",
       " 0.9827999999999999]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testaccuracypernoisemean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9829070634920634\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(testaccuracypernoisemean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0005000000000000004,\n",
       " 0.0021602468994692888,\n",
       " 0.0020615528128088323,\n",
       " 0.0025768197453450276,\n",
       " 0.0029107081994288325,\n",
       " 0.0027994168488950635,\n",
       " 0.002633913438213187,\n",
       " 0.0025434495871688016,\n",
       " 0.002638181191654586]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testaccuracyvariancepernoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9952333354949952,\n",
       " 0.9952708354592323,\n",
       " 0.9954166689515113,\n",
       " 0.9954746552556752,\n",
       " 0.9954894473552702,\n",
       " 0.9954682898024716,\n",
       " 0.9954593280383517,\n",
       " 0.9954406278207898,\n",
       " 0.9954574103156726,\n",
       " 0.995430141746998]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traningmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 3.749996423718649e-05,\n",
       " 0.00020850015144469053,\n",
       " 0.0002066191406334811,\n",
       " 0.00018715875684192703,\n",
       " 0.00017728097403360468,\n",
       " 0.00016559176032112665,\n",
       " 0.00016260670084146565,\n",
       " 0.00016048761355859546,\n",
       " 0.00017283755446450202]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingvariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9975000023841858]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfoldmeanpermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0019364898263213358]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfoldvariancepermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
