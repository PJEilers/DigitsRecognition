{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline cnn model for digit\n",
    "import numpy as np\n",
    "#import import_ipynb\n",
    "from loader import Loader\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import BatchNormalization\n",
    "import random as r\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from matplotlib import pyplot\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "from keras.utils.vis_utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset1():\n",
    "# Dividing the data into train and test data\n",
    "    #clear = lambda: os.system('clear')\n",
    "    #clear()\n",
    "    \n",
    "    dataset = Loader()\n",
    "    noise = 1\n",
    "    print(noise)\n",
    "    \n",
    "    trainX,trainY =  dataset.getWholeTrainSet(pca=False) \n",
    "    \n",
    "    \n",
    "    trainXaug,trainYaug =  dataset.augment() \n",
    "    \n",
    "    trainXaug1 = np.concatenate((trainX, trainXaug))\n",
    "    trainYaug1 = np.concatenate((trainY, trainY))\n",
    "    print(trainYaug1.shape)\n",
    "    trainXwithnoise, trainYwithnoise = dataset.getNoisySet(intensity=noise, set=\"train\", flat=False)\n",
    "    \n",
    "    testX, testY = dataset.getWholeTestSet()\n",
    "    \n",
    "    trainX = np.array(trainX)\n",
    "    trainXwithnoise = np.array(trainXwithnoise)\n",
    "    trainY = np.array(trainY)\n",
    "    testX = np.array(testX)\n",
    "    testY = np.array(testY)\n",
    "   \n",
    "    trainXwithnoise = trainXwithnoise.reshape((trainXwithnoise.shape[0], 16,15, 1))\n",
    "    trainXaug1 =  trainXaug1.reshape((trainXaug1.shape[0], 16,15, 1))\n",
    "    testX = testX.reshape((testX.shape[0], 16,15, 1))\n",
    "    trainX = trainX.reshape((trainX.shape[0], 16,15, 1))\n",
    "    # the labels are one hot encoded\n",
    "    testYintegers = testY\n",
    "    trainYaug1 =  to_categorical(trainYaug1)\n",
    "    testY = to_categorical(testY)\n",
    "    trainY = to_categorical(trainY)\n",
    "    return trainXaug1,trainXwithnoise, trainYaug1, testX, testY,testYintegers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdataset1(intensity,dataset):\n",
    "    \n",
    "    trainX,trainXwithnoise, trainY, testX, testY,testYintegers = dataset1(intensity,dataset)\n",
    "    return trainX,trainXwithnoise, trainY, testX, testY,testYintegers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_definition():\n",
    "    # tune model parameters here\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(16,15, 1)))\n",
    "    #model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Flatten and apply drop out or apply drop out after Conv2D it is essentially the same\n",
    "    model.add(Dropout(0.50))\n",
    "    model.add(Dense(240, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    \n",
    "    model.add(Dropout(0.20))\n",
    "    model.add(Dense(120, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dropout(0.20))\n",
    "    model.add(Dense(50, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#    model.add(Dropout(0.20))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    #opt = SGD(lr=0.01)\n",
    "    opt = SGD(lr=0.03, momentum=0.9)\n",
    "    #opt = 'adam'\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 13, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 14, 13, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 7, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 240)               322800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 240)               960       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 240)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               28920     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 120)               480       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 360,368\n",
      "Trainable params: 359,484\n",
      "Non-trainable params: 884\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_modelkfold(mtrainX,mtrainXwithnoise, mtrainY, folds=10):\n",
    "    accuracies,histories = list(), list()\n",
    "\n",
    "    kfold = KFold(folds, shuffle=True,random_state=3)      \n",
    "    print(mtrainX.shape)\n",
    "    print(mtrainY.shape)\n",
    "    for training_indices, testing_indices in kfold.split(mtrainX):\n",
    "        model = model_definition()\n",
    "        trainX, trainY, testX, testY = mtrainX[training_indices], mtrainY[training_indices], mtrainX[testing_indices], mtrainY[testing_indices]\n",
    "        # so this model.fit reflects the model.fit for only the kfold \n",
    "        #model.fit(trainX, trainY, epochs=120, batch_size=10, validation_data=(testX, testY), verbose=0)\n",
    "        history_kfold = model.fit(trainX, trainY, epochs=200, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
    "        \n",
    "        # returning the validation accuracies of every k fold validation set\n",
    "        _, accuraccy = model.evaluate(testX, testY, verbose=0)\n",
    "        print('%.3f' % (accuraccy * 100.0))\n",
    "        # stores accuracies and test data on last kth model\n",
    "        accuracies.append(accuraccy)\n",
    "        histories.append(history_kfold)\n",
    "        # implement a list for storing all the k fold models. If you wish\n",
    "    return accuracies,histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print the accuracies of the k fold iterations\n",
    "def fitmodel(trainX, trainY,testX, testY,i):   \n",
    "    \n",
    "    #once the model has been decided on from k fold\n",
    "    model = model_definition()\n",
    "    model.fit(trainX, trainY,epochs=200, verbose=0)\n",
    "    # save model\n",
    "    name = \"final_model.h5\" + str(i)\n",
    "    model.save(name)\n",
    "    # load the model\n",
    "    model = load_model(name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelpredictions(modellist,testX,testY):\n",
    "    \n",
    "    \n",
    "    correctpernoise = []\n",
    "    for model in modellist:\n",
    "        correctaveragepermodel = 0.0\n",
    "        correct = 0.0\n",
    "        preds = model.predict(testX)\n",
    "        print(preds.shape)\n",
    "        preds = np.argmax(model.predict(testX), axis=-1)\n",
    "        #preds = to_categorical(preds)\n",
    "        #print(preds)\n",
    "        \n",
    "        for i in range(len(testY)):\n",
    "            if (preds[i] == testY[i]): # Change\n",
    "                correct = correct+1\n",
    "                \n",
    "        correctaveragepermodel = correct/len(testY)\n",
    "        correctpernoise.append(correctaveragepermodel)\n",
    "        print(correctaveragepermodel)\n",
    "        #return list\n",
    "    return correctpernoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results():\n",
    "    modellist = []\n",
    "    finalresultmodelnonoiselist = []\n",
    "    numofmodels = 10\n",
    "    #intensities = [.05, 0.4]#, .1, .15, .20, .25, .30, .35, .40, .45, .50]\n",
    "    \n",
    "    #datasetlist = [Loader() for i in range(2)]\n",
    "    modellist = []\n",
    "    trainX,trainXwithnoise, trainY, testX, testY,testYintegers = dataset1()\n",
    "    print(trainY.shape)\n",
    "    # trainXwithnoise1,train_norm1, test_norm1= normalise_data(trainXwithnoise,trainX,testX) \n",
    "    print('printing the k fold accuracies with noisy training data')\n",
    "    accuracies, histories = train_modelkfold(trainX,trainXwithnoise, trainY)  \n",
    "    #accuracies, histories = train_modelkfold(trainX,trainXwithnoise, trainY)\n",
    "\n",
    "    finalresultpernoise = 0\n",
    "    # making 5 models\n",
    "    for i in range(numofmodels):\n",
    "        model = fitmodel(trainX, trainY,testX, testY,i)\n",
    "        modellist.append(model)\n",
    "\n",
    "    correct = 0    \n",
    "    correctpermodel = modelpredictions(modellist,testX,testYintegers)\n",
    "\n",
    "\n",
    "    finalresultmodelnonoise = (sum(correctpermodel)/numofmodels)*100\n",
    "    finalresultmodelnonoiselist.append(finalresultmodelnonoise)\n",
    "    ###########################################################################\n",
    "    #trainXwithnoise = trainXwithnoise.reshape((trainXwithnoise.shape[0], 16,15, 1))\n",
    "    #testX = testX.reshape((testX.shape[0], 16,15, 1))\n",
    "    #trainX = trainX.reshape((trainX.shape[0], 16,15, 1))\n",
    "    #train_norm = train_norm.reshape((trainX.shape[0], 16,15, 1))\n",
    "    ###########################################################################\n",
    "    %reset -f in\n",
    "    return finalresultmodelnonoiselist\n",
    "    #predslist.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(2000,)\n",
      "(2000, 10)\n",
      "printing the k fold accuracies with noisy training data\n",
      "(2000, 16, 15, 1)\n",
      "(2000, 10)\n",
      "100.000\n",
      "99.500\n",
      "99.000\n",
      "99.000\n",
      "98.500\n",
      "100.000\n",
      "99.500\n",
      "100.000\n",
      "99.500\n",
      "100.000\n",
      "WARNING:tensorflow:From /home/gebruiker/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/gebruiker/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: final_model.h50/assets\n",
      "INFO:tensorflow:Assets written to: final_model.h51/assets\n",
      "INFO:tensorflow:Assets written to: final_model.h52/assets\n",
      "INFO:tensorflow:Assets written to: final_model.h53/assets\n",
      "INFO:tensorflow:Assets written to: final_model.h54/assets\n",
      "INFO:tensorflow:Assets written to: final_model.h55/assets\n",
      "INFO:tensorflow:Assets written to: final_model.h56/assets\n",
      "INFO:tensorflow:Assets written to: final_model.h57/assets\n",
      "INFO:tensorflow:Assets written to: final_model.h58/assets\n",
      "INFO:tensorflow:Assets written to: final_model.h59/assets\n",
      "(1000, 10)\n",
      "0.982\n",
      "(1000, 10)\n",
      "0.983\n",
      "(1000, 10)\n",
      "0.984\n",
      "(1000, 10)\n",
      "0.983\n",
      "(1000, 10)\n",
      "0.982\n",
      "(1000, 10)\n",
      "0.984\n",
      "(1000, 10)\n",
      "0.984\n",
      "(1000, 10)\n",
      "0.983\n",
      "(1000, 10)\n",
      "0.985\n",
      "(1000, 10)\n",
      "0.984\n",
      "Flushing input history\n"
     ]
    }
   ],
   "source": [
    "result = results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[98.33999999999999]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
