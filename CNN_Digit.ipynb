{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline cnn model for digit\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import BatchNormalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "input = np.loadtxt(\"mfeat-pix.txt\", dtype='i')\n",
    "#Converting the dataset into a 2D matrix\n",
    "input_2D = np.reshape(input,(2000,16,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset():\n",
    "# Dividing the data into train and test data\n",
    "    testX = np.zeros((400,16,15))\n",
    "    trainX = np.zeros((1600,16,15))\n",
    "    testY = np.zeros((400,1), dtype = 'uint')\n",
    "    trainY = np.zeros((1600,1), dtype = 'uint')\n",
    "\n",
    "    for i in range(10):\n",
    "        # Taking last 40 examples per example for test and 16 for train\n",
    "        testX[(i*40):((i+1)*40)] = input_2D[(200*i)+159:(200*i+199)]\n",
    "        trainX[(i*160):((i+1)*160-1)] = input_2D[(200*i):(200*i)+159]\n",
    "        # Labels\n",
    "        testY[(i*40):((i+1)*40)] = i\n",
    "        trainY[(i*160):((i+1)*160-1)] = i\n",
    "    trainX = trainX.reshape((trainX.shape[0], 16, 15, 1))\n",
    "    testX = testX.reshape((testX.shape[0], 16, 15, 1))\n",
    "    testY = to_categorical(testY)\n",
    "    trainY = to_categorical(trainY)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data normalization\n",
    "def normalise_data(traindata, testdata):\n",
    "    traindata = traindata.astype('float32')\n",
    "    testdata = testdata.astype('float32')\n",
    "    train_norm = traindata / 6.0\n",
    "    test_norm = testdata / 6.0\n",
    "    return train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_definition():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(16, 15, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    # softmax for multimodal classification\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    opt = SGD(lr=0.005)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(mtrainX, mtrainY, folds=5):\n",
    "    accuracies = list()\n",
    "    # random shuffle k fold validation\n",
    "    kfold = KFold(folds, shuffle=True, random_state=3)\n",
    "    for training_indices, testing_indices in kfold.split(mtrainX):\n",
    "        model = model_definition()\n",
    "        trainX, trainY, testX, testY = mtrainX[training_indices], mtrainY[training_indices], mtrainX[testing_indices], mtrainY[testing_indices]\n",
    "        model.fit(trainX, trainY, epochs=50, batch_size=8, validation_data=(testX, testY), verbose=0)\n",
    "        _, accuraccy = model.evaluate(testX, testY, verbose=0)\n",
    "        print('%.3f' % (accuraccy * 100.0))\n",
    "        # stores accuracies and test data on last kth model\n",
    "        accuracies.append(accuraccy)\n",
    "    return accuracies, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model():\n",
    "    trainX, trainY, testX, testY = dataset()\n",
    "    trainX, testX = normalise_data(trainX, testX)\n",
    "    # training model\n",
    "    accuracies,model = train_model(trainX, trainY)\n",
    "    # Test model on kth trained model\n",
    "    _, accuracy1 = model.evaluate(testX, testY, verbose=0)\n",
    "    print('Test accuracy =',accuracy1*100.0)\n",
    "    return accuracy1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.125\n",
      "97.188\n",
      "96.875\n",
      "97.188\n",
      "96.250\n",
      "Test accuracy = 98.25000166893005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9825000166893005"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
