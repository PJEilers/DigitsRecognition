{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from loader.ipynb\n"
     ]
    }
   ],
   "source": [
    "# baseline cnn model for digit\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "from loader import Loader\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import BatchNormalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset1():\n",
    "# Dividing the data into train and test data\n",
    "    dataset = Loader()\n",
    "    dataset.pca()\n",
    "    trainX, trainY = dataset.getWholeTrainSet(pca=False)\n",
    "    testX, testY = dataset.getWholeTestSet(pca=False)\n",
    "    trainX = np.array(trainX)\n",
    "    trainY = np.array(trainY)\n",
    "    testX = np.array(testX)\n",
    "    testY = np.array(testY)\n",
    "    \n",
    "    trainX = trainX.reshape((trainX.shape[0], 16,15, 1))\n",
    "    testX = testX.reshape((testX.shape[0], 16,15, 1))\n",
    "    testY = to_categorical(testY)\n",
    "    trainY = to_categorical(trainY)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data normalization\n",
    "def normalise_data(traindata, testdata):\n",
    "    traindata = traindata.astype('float32')\n",
    "    testdata = testdata.astype('float32')\n",
    "    train_norm = traindata / 6.0\n",
    "    test_norm = testdata / 6.0\n",
    "    return train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_definition():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(16,15, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "#    model.add(Dropout(0.50))\n",
    "    \n",
    "\n",
    "#    model.add(Conv2D(16, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(16,15, 1)))\n",
    "#    model.add(BatchNormalization())\n",
    "#    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Flatten and apply drop out or apply drop out after Conv2D it is essentially the same\n",
    "    model.add(Dropout(0.50))\n",
    "    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "  #  model.add(Dropout(0.20))\n",
    "    model.add(Dense(50, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    \n",
    "    model.add(Dropout(0.20))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    opt = SGD(lr=0.01)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(mtrainX, mtrainY, folds=5):\n",
    "    accuracies = list()\n",
    "    # random shuffle k fold validation\n",
    "    kfold = KFold(folds, shuffle=True, random_state=3)\n",
    "    for training_indices, testing_indices in kfold.split(mtrainX):\n",
    "        model = model_definition()\n",
    "        trainX, trainY, testX, testY = mtrainX[training_indices], mtrainY[training_indices], mtrainX[testing_indices], mtrainY[testing_indices]\n",
    "        model.fit(trainX, trainY, epochs=120, batch_size=10, validation_data=(testX, testY), verbose=0)\n",
    "        _, accuraccy = model.evaluate(testX, testY, verbose=0)\n",
    "        print('%.3f' % (accuraccy * 100.0))\n",
    "        # stores accuracies and test data on last kth model\n",
    "        accuracies.append(accuraccy)\n",
    "    return accuracies, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model():\n",
    "    trainX, trainY, testX, testY = dataset1()\n",
    " #   trainX, testX = normalise_data(trainX, testX)\n",
    "    # training model\n",
    "    accuracies,model = train_model(trainX, trainY)\n",
    "    # Test model on kth trained model\n",
    "    _, accuracy1 = model.evaluate(testX, testY, verbose=0)\n",
    "    print('Test accuracy =',accuracy1*100.0)\n",
    "    return accuracy1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.500\n",
      "96.500\n",
      "98.500\n",
      "97.500\n",
      "99.000\n",
      "Test accuracy = 97.79999852180481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9779999852180481"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
